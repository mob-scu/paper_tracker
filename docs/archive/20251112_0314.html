<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2025-11-12 03:14</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20251112_0314</div>
    <div class="row"><div class="card">
<div class="title">AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks</div>
<div class="meta-line">Authors: Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu</div>
<div class="meta-line">First: 2024-03-02T16:52:22+00:00 · Latest: 2024-11-15T01:50:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/pdf/2403.04783v2">Abs</a> · <a href="https://github.com/XHMY/AutoDefense">Code1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AutoDefense：针对越狱攻击的多智能体LLM防御</div>
<div class="mono" style="margin-top:8px">尽管经过广泛的道德对齐预训练以防止生成有害信息，大型语言模型（LLMs）仍然容易受到越狱攻击。本文提出了AutoDefense，一个多智能体防御框架，能够过滤LLMs的有害响应。通过响应过滤机制，我们的框架对不同的越狱攻击提示具有鲁棒性，并可用于防御不同的受害模型。AutoDefense为LLM智能体分配不同角色，并使其协作完成防御任务。任务的分工增强了LLMs的整体指令遵循能力，并使其他防御组件能够作为工具集成。借助AutoDefense，小型开源LM可以作为智能体，保护大型模型免受越狱攻击。我们的实验表明，AutoDefense能够有效防御不同的越狱攻击，同时保持正常用户请求的性能。例如，我们使用LLaMA-2-13b和3智能体系统将GPT-3.5的攻击成功率从55.74%降低到7.95%。我们的代码和数据可在https://github.com/XHMY/AutoDefense公开获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the vulnerability of large language models (LLMs) to jailbreak attacks, despite their pre-training for moral alignment. Previous methods have struggled to effectively filter harmful responses, leading to a need for a more robust solution. The proposed AutoDefense framework introduces a multi-agent system that collaboratively filters harmful outputs by assigning distinct roles to LLM agents, enhancing their instruction-following capabilities and allowing for the integration of additional defense tools. This approach is well-motivated as it enables smaller open-source models to defend larger ones against attacks. The methodology demonstrates significant effectiveness, achieving a reduction in the attack success rate on GPT-3.5 from 55.74% to 7.95% using a three-agent system, while maintaining performance during normal user interactions.</div>
<div class="mono" style="margin-top:8px">本文探讨了大型语言模型（LLMs）在道德对齐预训练后仍然容易受到越狱攻击的脆弱性。以往的方法在有效过滤有害响应方面存在困难，因此需要一种更强大的解决方案。所提出的AutoDefense框架引入了一个多代理系统，通过为LLM代理分配不同角色，协同过滤有害输出，从而增强其指令跟随能力，并允许集成其他防御工具。该方法显示出显著的有效性，使用LLaMA-2-13b的3代理系统将GPT-3.5的攻击成功率从55.74%降低到7.95%，因此支持在正常用户交互中保持性能的同时防御攻击的目标。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251111_0349.html">20251111_0349</a>
<a href="archive/20251110_0329.html">20251110_0329</a>
<a href="archive/20251109_0314.html">20251109_0314</a>
<a href="archive/20251108_0315.html">20251108_0315</a>
<a href="archive/20251107_0317.html">20251107_0317</a>
<a href="archive/20251106_0349.html">20251106_0349</a>
<a href="archive/20251105_0321.html">20251105_0321</a>
<a href="archive/20251104_1539.html">20251104_1539</a>
<a href="archive/20251104_0324.html">20251104_0324</a>
<a href="archive/20251103_0315.html">20251103_0315</a>
<a href="archive/20251102_1356.html">20251102_1356</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
